{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:28.631216Z",
     "iopub.status.busy": "2022-04-27T09:07:28.630919Z",
     "iopub.status.idle": "2022-04-27T09:07:28.640376Z",
     "shell.execute_reply": "2022-04-27T09:07:28.639441Z",
     "shell.execute_reply.started": "2022-04-27T09:07:28.631184Z"
    }
   },
   "outputs": [],
   "source": [
    "#%cd '/kaggle/input/dl-th-da/proj/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:31.558875Z",
     "iopub.status.busy": "2022-04-27T09:07:31.558606Z",
     "iopub.status.idle": "2022-04-27T09:07:31.564919Z",
     "shell.execute_reply": "2022-04-27T09:07:31.564026Z",
     "shell.execute_reply.started": "2022-04-27T09:07:31.558847Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "#from torchvision.io import read_image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:14.130945Z",
     "iopub.status.busy": "2022-04-27T09:07:14.130448Z",
     "iopub.status.idle": "2022-04-27T09:07:14.135801Z",
     "shell.execute_reply": "2022-04-27T09:07:14.134506Z",
     "shell.execute_reply.started": "2022-04-27T09:07:14.130907Z"
    }
   },
   "outputs": [],
   "source": [
    "root = 'dataset'\n",
    "IMG_SIZE = 32\n",
    "BATCH_SIZE = 32\n",
    "lr = 1e-3\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:33.264490Z",
     "iopub.status.busy": "2022-04-27T09:07:33.263742Z",
     "iopub.status.idle": "2022-04-27T09:07:34.424895Z",
     "shell.execute_reply": "2022-04-27T09:07:34.424221Z",
     "shell.execute_reply.started": "2022-04-27T09:07:33.264445Z"
    }
   },
   "outputs": [],
   "source": [
    "source_images = np.load('dataset/X_new_rgb.npy')\n",
    "source_labels = np.load('dataset/Y_c1.npy')\n",
    "\n",
    "target_images = np.load('dataset/X_new_th.npy')\n",
    "target_labels = np.load('dataset/Y.npy')\n",
    "\n",
    "source_images.shape, target_images.shape, source_labels.shape, target_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_images.dtype, source_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:36.645179Z",
     "iopub.status.busy": "2022-04-27T09:07:36.644508Z",
     "iopub.status.idle": "2022-04-27T09:07:36.651612Z",
     "shell.execute_reply": "2022-04-27T09:07:36.650762Z",
     "shell.execute_reply.started": "2022-04-27T09:07:36.645139Z"
    }
   },
   "outputs": [],
   "source": [
    "target_labels = np.squeeze(target_labels,1)\n",
    "target_images.shape, target_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:38.518817Z",
     "iopub.status.busy": "2022-04-27T09:07:38.518412Z",
     "iopub.status.idle": "2022-04-27T09:07:38.570993Z",
     "shell.execute_reply": "2022-04-27T09:07:38.570255Z",
     "shell.execute_reply.started": "2022-04-27T09:07:38.518782Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "source_train_images, source_test_images, source_train_labels, source_test_labels = train_test_split(source_images, source_labels, test_size=0.2, random_state=42, stratify=source_labels)\n",
    "target_train_images, target_test_images, target_train_labels, target_test_labels = train_test_split(target_images, target_labels, test_size=0.6, random_state=42, stratify=target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T05:43:59.785427Z",
     "iopub.status.busy": "2022-04-27T05:43:59.784987Z",
     "iopub.status.idle": "2022-04-27T05:43:59.793528Z",
     "shell.execute_reply": "2022-04-27T05:43:59.79254Z",
     "shell.execute_reply.started": "2022-04-27T05:43:59.785392Z"
    }
   },
   "outputs": [],
   "source": [
    "len(source_train_images), len(target_train_images), len(source_test_images), len(target_test_images), source_train_images.dtype, source_train_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:45.106384Z",
     "iopub.status.busy": "2022-04-27T09:07:45.106102Z",
     "iopub.status.idle": "2022-04-27T09:07:45.113830Z",
     "shell.execute_reply": "2022-04-27T09:07:45.112869Z",
     "shell.execute_reply.started": "2022-04-27T09:07:45.106353Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_array, label_array, transform=None):\n",
    "\n",
    "        self.labels = label_array#np.load(label_file)\n",
    "        self.images = img_array#np.load(img_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.images[idx]#.astype(int)\n",
    "        PIL_image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "        label = self.labels[idx]#.astype(int)\n",
    "        #sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(PIL_image)\n",
    "            #image = image.transpose(2, 0, 1)\n",
    "            #print('------------',image.shape)\n",
    "\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:47.888153Z",
     "iopub.status.busy": "2022-04-27T09:07:47.887586Z",
     "iopub.status.idle": "2022-04-27T09:07:47.893174Z",
     "shell.execute_reply": "2022-04-27T09:07:47.892273Z",
     "shell.execute_reply.started": "2022-04-27T09:07:47.888118Z"
    }
   },
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "BATCH_SIZE = 32\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((img_size,img_size)),\n",
    "    #transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.675 , 0.646, 0.616], std=[0.141, 0.158 , 0.186]),\n",
    "    ])\n",
    "\n",
    "preprocess_target = transforms.Compose([\n",
    "  transforms.Resize((img_size,img_size)),\n",
    "  #transforms.CenterCrop(299),\n",
    "  transforms.ToTensor(),\n",
    "  #transforms.Normalize(mean=[0.413, 0.413, 0.413], std=[0.215, 0.215, 0.215]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:49.302485Z",
     "iopub.status.busy": "2022-04-27T09:07:49.301732Z",
     "iopub.status.idle": "2022-04-27T09:07:49.308934Z",
     "shell.execute_reply": "2022-04-27T09:07:49.308263Z",
     "shell.execute_reply.started": "2022-04-27T09:07:49.302449Z"
    }
   },
   "outputs": [],
   "source": [
    "train = CustomDataset(\n",
    "    img_array=source_train_images,\n",
    "    label_array=source_train_labels,\n",
    "    transform=preprocess)\n",
    "\n",
    "#torch.utils.data.TensorDataset(torch.from_numpy(img_rgb_train), torch.from_numpy(labels_rgb_train))\n",
    "test = CustomDataset(\n",
    "    img_array=source_test_images,\n",
    "    label_array=source_test_labels,\n",
    "    transform=preprocess)\n",
    "\n",
    "train_th = CustomDataset(\n",
    "    img_array=target_train_images,\n",
    "    label_array=target_train_labels,\n",
    "    transform=preprocess_target)\n",
    "test_th = CustomDataset(\n",
    "    img_array=target_test_images,\n",
    "    label_array=target_test_labels,\n",
    "    transform=preprocess_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:51.285960Z",
     "iopub.status.busy": "2022-04-27T09:07:51.285284Z",
     "iopub.status.idle": "2022-04-27T09:07:51.291576Z",
     "shell.execute_reply": "2022-04-27T09:07:51.290745Z",
     "shell.execute_reply.started": "2022-04-27T09:07:51.285924Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_source_test = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_source = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_target_test = DataLoader(train_th, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_target = DataLoader(train_th, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T05:44:28.996318Z",
     "iopub.status.busy": "2022-04-27T05:44:28.996055Z",
     "iopub.status.idle": "2022-04-27T05:44:29.073479Z",
     "shell.execute_reply": "2022-04-27T05:44:29.072555Z",
     "shell.execute_reply.started": "2022-04-27T05:44:28.99629Z"
    }
   },
   "source": [
    "iter_source_test = iter(dataloader_target)\n",
    "for batch in range(3):\n",
    "    i,l = iter_source_test.next()\n",
    "    break\n",
    "\n",
    "print(i.shape, l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset from numpy, resnet, densenet, alexnet, mobilenet, vgg for transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T09:07:55.568550Z",
     "iopub.status.busy": "2022-04-27T09:07:55.567656Z",
     "iopub.status.idle": "2022-04-27T09:07:55.574173Z",
     "shell.execute_reply": "2022-04-27T09:07:55.573488Z",
     "shell.execute_reply.started": "2022-04-27T09:07:55.568500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "#Ref: https://pytorch.org/tutorials/beginner/examples_autograd/polynomial_custom_function.html\n",
    "class GRL(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, features,lambda_):\n",
    "        ctx.lambda_ = lambda_  #ctx.save_for_backward(input)\n",
    "        return features\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.lambda_, None #input, = ctx.saved_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "pre =  models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:19:42.526040Z",
     "iopub.status.busy": "2022-04-27T11:19:42.525788Z",
     "iopub.status.idle": "2022-04-27T11:19:42.534759Z",
     "shell.execute_reply": "2022-04-27T11:19:42.533999Z",
     "shell.execute_reply.started": "2022-04-27T11:19:42.526014Z"
    }
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for p in pre.features.parameters():\n",
    "    print(i,p.shape)#requires_grad = False - Use this to determine number to freeze in model below\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:25:06.691034Z",
     "iopub.status.busy": "2022-04-27T13:25:06.690776Z",
     "iopub.status.idle": "2022-04-27T13:25:06.706741Z",
     "shell.execute_reply": "2022-04-27T13:25:06.705971Z",
     "shell.execute_reply.started": "2022-04-27T13:25:06.691007Z"
    }
   },
   "outputs": [],
   "source": [
    "#Ref: https://towardsdatascience.com/practical-transfer-learning-with-pytorch-8344e5c82f59\n",
    "class UDA(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(UDA, self).__init__()\n",
    "        \n",
    "        self.feature = base_model.features \n",
    "        \n",
    "        for i,p in enumerate(self.feature.parameters()):\n",
    "        #   if(i<2): [changed to [2,4,6] depending on how many conv layers to freeze]\n",
    "            p.requires_grad = False\n",
    "        #current setting: all layers frozen\n",
    "        \n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('c_fc1', nn.Linear(256*6*6, 100))\n",
    "        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(100))\n",
    "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_drop1', nn.Dropout2d())\n",
    "        self.class_classifier.add_module('c_fc2', nn.Linear(100, 100))\n",
    "        self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(100))\n",
    "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc3', nn.Linear(100, 10))\n",
    "        self.class_classifier.add_module('c_softmax', nn.LogSoftmax())\n",
    "\n",
    "        self.domain_classifier = nn.Sequential()\n",
    "        self.domain_classifier.add_module('d_fc1', nn.Linear(256*6*6, 100))\n",
    "        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))\n",
    "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
    "        self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))\n",
    "        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n",
    "  \n",
    "    # x represents our data\n",
    "    def forward(self, x,lambda_):\n",
    "\n",
    "        feature = self.feature(x)\n",
    "        #print(feature.shape)\n",
    "        feature = feature.view(-1, np.prod(feature.shape[1:])) #256*6*6 for alexnet\n",
    "        \n",
    "        grl = GRL.apply(feature, lambda_) #elementwise\n",
    "        pred_label = self.class_classifier(feature)\n",
    "        domain_label = self.domain_classifier(grl)\n",
    "        return pred_label, domain_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:25:11.252116Z",
     "iopub.status.busy": "2022-04-27T13:25:11.251566Z",
     "iopub.status.idle": "2022-04-27T13:25:11.957479Z",
     "shell.execute_reply": "2022-04-27T13:25:11.956741Z",
     "shell.execute_reply.started": "2022-04-27T13:25:11.252065Z"
    }
   },
   "outputs": [],
   "source": [
    "model = UDA(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T10:56:39.758822Z",
     "iopub.status.busy": "2022-04-27T10:56:39.758270Z",
     "iopub.status.idle": "2022-04-27T10:56:39.762526Z",
     "shell.execute_reply": "2022-04-27T10:56:39.761674Z",
     "shell.execute_reply.started": "2022-04-27T10:56:39.758787Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda = True\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:25:21.049035Z",
     "iopub.status.busy": "2022-04-27T13:25:21.048779Z",
     "iopub.status.idle": "2022-04-27T13:25:21.061913Z",
     "shell.execute_reply": "2022-04-27T13:25:21.061216Z",
     "shell.execute_reply.started": "2022-04-27T13:25:21.049007Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)#, weight_decay=0.0005)\n",
    "\n",
    "loss_label = torch.nn.NLLLoss()\n",
    "loss_domain = torch.nn.NLLLoss()\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "    loss_label = loss_label.cuda()\n",
    "    loss_domain = loss_domain.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T10:56:45.901352Z",
     "iopub.status.busy": "2022-04-27T10:56:45.900809Z",
     "iopub.status.idle": "2022-04-27T10:56:45.905789Z",
     "shell.execute_reply": "2022-04-27T10:56:45.905060Z",
     "shell.execute_reply.started": "2022-04-27T10:56:45.901305Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_acc(pred, target):\n",
    "    #preds =  pred.argmax(dim=1)\n",
    "    preds = pred.data.max(1, keepdim=True)[1]\n",
    "    correct = preds.eq(target.data.view_as(preds)).sum()\n",
    "    \n",
    "    return correct#/len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:25:26.057713Z",
     "iopub.status.busy": "2022-04-27T13:25:26.057240Z",
     "iopub.status.idle": "2022-04-27T13:25:26.072073Z",
     "shell.execute_reply": "2022-04-27T13:25:26.071280Z",
     "shell.execute_reply.started": "2022-04-27T13:25:26.057672Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model=model,dataloader_source_test=dataloader_source_test, dataloader_target_test=dataloader_target_test, BATCH_SIZE=BATCH_SIZE):\n",
    "    len_dataloader = min(len(dataloader_source_test), len(dataloader_target_test))\n",
    "    iter_source_test = iter(dataloader_source_test)\n",
    "    iter_target_test = iter(dataloader_target_test)\n",
    "    error_source_label=0\n",
    "    error_source_domain=0\n",
    "    error_target_label=0\n",
    "    error_target_domain=0\n",
    "    source_classification_acc = 0\n",
    "    source_domain_acc = 0\n",
    "    target_classification_acc = 0\n",
    "    target_domain_acc = 0\n",
    "    n_total=0\n",
    "    \n",
    "    \n",
    "    for i in range(len_dataloader):\n",
    "        \n",
    "        p = float(i + len_dataloader)  / len_dataloader #ratio of training\n",
    "        lambda_ = (2/(1 + np.exp(-10 * p))) -1\n",
    "    \n",
    "        img_source, lab_source  = iter_source_test.next()\n",
    "        batch_size = len(lab_source)\n",
    "        lab_domain = torch.zeros(batch_size).long()\n",
    "        if cuda:\n",
    "            img_source = img_source.cuda()\n",
    "            lab_source = lab_source.cuda()\n",
    "            lab_domain = lab_domain.cuda()\n",
    "        pred_label, domain_label = model(img_source, lambda_)\n",
    "        lab_source = lab_source.to(torch.long)\n",
    "       \n",
    "        error_source_label+= loss_label(pred_label, lab_source)\n",
    "        error_source_domain += loss_domain(domain_label, lab_domain)\n",
    "        \n",
    "        #preds = pred_label.data.max(1, keepdim=True)[1]\n",
    "        #correct_source_cls = preds.eq(lab_source.data.view_as(pred_label)).sum()\n",
    "        n_total += BATCH_SIZE\n",
    "    \n",
    "        source_classification_acc+= get_acc(pred_label, lab_source)\n",
    "        source_domain_acc += get_acc(domain_label, lab_domain)\n",
    "    \n",
    "        data_target = iter_target_test.next()\n",
    "        img_target, lab_target = data_target\n",
    "        batch_size = len(lab_target)\n",
    "        lab_domain = torch.ones(batch_size).long()\n",
    "        if cuda:\n",
    "            img_target = img_target.cuda()\n",
    "            lab_target = lab_target.cuda()\n",
    "            lab_domain = lab_domain.cuda()\n",
    "        pred_label, domain_label = model(img_target, lambda_)\n",
    "        \n",
    "        lab_target = lab_target.to(torch.long)\n",
    "        error_target_label+= loss_label(pred_label, lab_target)\n",
    "        error_target_domain += loss_domain(domain_label, lab_domain)\n",
    "        \n",
    "        target_classification_acc += get_acc(pred_label, lab_target)\n",
    "        \n",
    "        \n",
    "        target_domain_acc += get_acc(domain_label, lab_domain)\n",
    "    \n",
    "    return (error_source_label/len_dataloader,error_source_domain/len_dataloader,error_target_label/len_dataloader,error_target_domain/len_dataloader,\n",
    "           source_classification_acc/n_total, target_classification_acc/n_total,source_domain_acc/n_total, target_domain_acc/n_total )\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:25:33.257461Z",
     "iopub.status.busy": "2022-04-27T13:25:33.256954Z",
     "iopub.status.idle": "2022-04-27T13:41:08.342674Z",
     "shell.execute_reply": "2022-04-27T13:41:08.341969Z",
     "shell.execute_reply.started": "2022-04-27T13:25:33.257417Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "best_acc = 0\n",
    "src_err=[]\n",
    "src_d_err=[]\n",
    "tgt_d_err=[]\n",
    "EPOCHS =200\n",
    "tgt_err=[]\n",
    "\n",
    "source_accu=[]\n",
    "target_accu=[]\n",
    "\n",
    "for ep in tqdm(range(EPOCHS),desc='Epochs: '):\n",
    "    \n",
    "    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n",
    "    iter_source = iter(dataloader_source)\n",
    "    iter_target = iter(dataloader_target)\n",
    "    model.train(True)\n",
    "    for i in range(len_dataloader):\n",
    "        p = float(i + ep*len_dataloader) / EPOCHS / len_dataloader #ratio of training\n",
    "        lambda_ = (2/(1 + np.exp(-10 * p))) -1\n",
    "        #SOURCE ITER\n",
    "        data_source = iter_source.next()\n",
    "        img_source, lab_source = data_source\n",
    "        batch_size = len(lab_source)\n",
    "        lab_domain = torch.zeros(batch_size).long()\n",
    "        model.zero_grad()\n",
    "        if cuda:\n",
    "            img_source = img_source.cuda()\n",
    "            lab_source = lab_source.cuda()\n",
    "            lab_domain = lab_domain.cuda()\n",
    "        \n",
    "        pred_label, domain_label = model(img_source, lambda_)\n",
    "\n",
    "        lab_source = lab_source.type(torch.LongTensor)\n",
    "        if cuda:\n",
    "            pred_label = pred_label.cuda()\n",
    "            domain_label = domain_label.cuda()\n",
    "            lab_source = lab_source.cuda()\n",
    "            \n",
    "        error_source_label= loss_label(pred_label, lab_source)\n",
    "        error_source_domain =loss_domain(domain_label, lab_domain)\n",
    "        \n",
    "        #TARGET ITER\n",
    "        data_target = iter_target.next()\n",
    "        img_target, lab_target = data_target\n",
    "        batch_size = len(lab_target)\n",
    "        lab_domain = torch.ones(batch_size).long()\n",
    "        #model.zero_grad()\n",
    "        if cuda:\n",
    "            img_target = img_target.cuda()\n",
    "            lab_target = lab_target.cuda()\n",
    "            lab_domain = lab_domain.cuda()\n",
    "            \n",
    "        pred_label, domain_label = model(img_target, lambda_)\n",
    "        \n",
    "        error_target_domain = loss_domain(domain_label, lab_domain)\n",
    "        \n",
    "        error = error_source_domain + error_target_domain + error_source_label\n",
    "        \n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    #Evaluate\n",
    "    model.train(False)\n",
    "    src_err.append(error_source_label.cpu().data.numpy())\n",
    "    src_d_err.append(error_source_domain.cpu().data.numpy())\n",
    "    tgt_d_err.append(error_target_domain.cpu().data.numpy())\n",
    "    #torch.save(my_net, '{0}/mnist_mnistm_model1_epoch_{1}.pth'.format('/content/drive/MyDrive/DANN/models/', epoch))\n",
    "    \n",
    "    error_source_label,error_source_domain,error_target_label,error_target_domain,a,b,c,d = evaluate()\n",
    "    print(f\"Source label classifier: {error_source_label.item()}\\n Source domain classifier: {error_source_domain.item()}\\n Target label classifier: {error_target_label.item()}\\n Target domain classifier:{error_target_domain.item()}\\n Source classification acc:{100*a.item()}\\n target_classification_acc:{100*b.item()}\\n\")# source_domain_acc:{100*c.item()}\\n  target_domain_acc:{100*d.item()}\\n\")\n",
    "    source_accu.append(a.cpu().data.numpy())\n",
    "    target_accu.append(b.cpu().data.numpy())\n",
    "    tgt_err.append(error_target_label.cpu().data.numpy())\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        #800\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:41:08.344702Z",
     "iopub.status.busy": "2022-04-27T13:41:08.344240Z",
     "iopub.status.idle": "2022-04-27T13:41:08.350945Z",
     "shell.execute_reply": "2022-04-27T13:41:08.350062Z",
     "shell.execute_reply.started": "2022-04-27T13:41:08.344655Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epoch = len(src_err)\n",
    "n_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:41:08.353001Z",
     "iopub.status.busy": "2022-04-27T13:41:08.351944Z",
     "iopub.status.idle": "2022-04-27T13:41:08.956809Z",
     "shell.execute_reply": "2022-04-27T13:41:08.956127Z",
     "shell.execute_reply.started": "2022-04-27T13:41:08.352963Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,n_epoch,1),np.array(src_err),label='Source')\n",
    "plt.plot(np.arange(0,n_epoch,1),np.array(tgt_err),label='Target')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Class Classification Error\")\n",
    "plt.legend()\n",
    "#plt.savefig('/content/drive/MyDrive/DANN/err1.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(0,n_epoch,1),np.array(src_d_err),label='Source')\n",
    "plt.plot(np.arange(0,n_epoch,1),np.array(tgt_d_err),label='Target')\n",
    "plt.title(\"Domain Classification Error\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend()\n",
    "#plt.savefig('err_alexnet.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(0,n_epoch,1),np.array(source_accu),label='Source')\n",
    "plt.plot(np.arange(0,n_epoch,1),np.array(target_accu),label='Target')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Class Classification Accuracy\")\n",
    "plt.legend()\n",
    "#plt.savefig('acc_alexnet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:43:19.440373Z",
     "iopub.status.busy": "2022-04-27T13:43:19.440059Z",
     "iopub.status.idle": "2022-04-27T13:43:19.445945Z",
     "shell.execute_reply": "2022-04-27T13:43:19.445261Z",
     "shell.execute_reply.started": "2022-04-27T13:43:19.440342Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(target_accu).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:43:20.376467Z",
     "iopub.status.busy": "2022-04-27T13:43:20.376180Z",
     "iopub.status.idle": "2022-04-27T13:43:20.382475Z",
     "shell.execute_reply": "2022-04-27T13:43:20.381717Z",
     "shell.execute_reply.started": "2022-04-27T13:43:20.376435Z"
    }
   },
   "outputs": [],
   "source": [
    "mp = np.array(target_accu).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T13:43:21.252522Z",
     "iopub.status.busy": "2022-04-27T13:43:21.251786Z",
     "iopub.status.idle": "2022-04-27T13:43:21.261586Z",
     "shell.execute_reply": "2022-04-27T13:43:21.260835Z",
     "shell.execute_reply.started": "2022-04-27T13:43:21.252485Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(source_accu)[mp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
